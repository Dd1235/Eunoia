{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa512ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating transcript...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OpenAI' object has no attribute 'ChatCompletion'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m prompt = \u001b[33m\"\u001b[39m\u001b[33mrelaxation and breath awareness\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating transcript...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m transcript = \u001b[43mgenerate_transcript\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTranscript:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, transcript)\n\u001b[32m     55\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating speech...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mgenerate_transcript\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_transcript\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m.create(\n\u001b[32m     14\u001b[39m         model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m         messages=[\n\u001b[32m     16\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mYou are a meditation guide. Keep output under 100 words.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     17\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreate a 1-minute calming meditation for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m},\n\u001b[32m     18\u001b[39m         ],\n\u001b[32m     19\u001b[39m     )\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m'\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m].strip()\n",
      "\u001b[31mAttributeError\u001b[39m: 'OpenAI' object has no attribute 'ChatCompletion'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "import asyncio\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from openai.helpers import LocalAudioPlayer\n",
    "\n",
    "client = OpenAI()\n",
    "# 1. Generate short meditation transcript (~60 seconds)\n",
    "def generate_transcript(prompt: str) -> str:\n",
    "    response = client.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a meditation guide. Keep output under 100 words.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Create a 1-minute calming meditation for: {prompt}\"},\n",
    "        ],\n",
    "    )\n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "\n",
    "\n",
    "openai = AsyncOpenAI()\n",
    "\n",
    "async def text_to_speech(text: str) -> None:\n",
    "    async with openai.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"coral\",\n",
    "        input=text,\n",
    "        instructions=\"Speak in calming tone to help the user meditate.\",\n",
    "        response_format=\"pcm\",\n",
    "    ) as response:\n",
    "        await LocalAudioPlayer().play(response)\n",
    "\n",
    "# 3. Mix with background\n",
    "def mix_with_background(voice: BytesIO, bg_path: str = \"Flowing_Focus.mp3\") -> AudioSegment:\n",
    "    speech = AudioSegment.from_file(voice, format=\"mp3\")\n",
    "    bg = AudioSegment.from_file(bg_path)\n",
    "\n",
    "    bg = bg - 15  # reduce background volume\n",
    "    bg = bg[:len(speech)] if len(bg) > len(speech) else bg * (len(speech) // len(bg) + 1)\n",
    "    bg = bg[:len(speech)]  # match length exactly\n",
    "\n",
    "    final = speech.overlay(bg)\n",
    "    return final\n",
    "\n",
    "# 4. Run pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = \"relaxation and breath awareness\"\n",
    "    print(\"Generating transcript...\")\n",
    "    transcript = generate_transcript(prompt)\n",
    "    print(\"Transcript:\\n\", transcript)\n",
    "\n",
    "    print(\"Generating speech...\")\n",
    "    speech_audio = text_to_speech(transcript)\n",
    "\n",
    "    print(\"Mixing with background...\")\n",
    "    final_audio = mix_with_background(speech_audio, \"background.mp3\")\n",
    "\n",
    "    print(\"Exporting...\")\n",
    "    final_audio.export(\"final_meditation.mp3\", format=\"mp3\")\n",
    "    print(\"âœ… Done: saved as final_meditation.mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1be284",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m openai.audio.speech.with_streaming_response.create(\n\u001b[32m     14\u001b[39m         model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini-tts\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m         voice=\u001b[33m\"\u001b[39m\u001b[33mcoral\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m         response_format=\u001b[33m\"\u001b[39m\u001b[33mpcm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m LocalAudioPlayer().play(response)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.11/asyncio/runners.py:186\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "from openai.helpers import LocalAudioPlayer\n",
    "\n",
    "# load dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai = AsyncOpenAI()\n",
    "\n",
    "async def main() -> None:\n",
    "    async with openai.audio.speech.with_streaming_response.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"coral\",\n",
    "        input=\"Today is a wonderful day to build something people love!\",\n",
    "        instructions=\"Speak in a cheerful and positive tone.\",\n",
    "        response_format=\"pcm\",\n",
    "    ) as response:\n",
    "        await LocalAudioPlayer().play(response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15930f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
